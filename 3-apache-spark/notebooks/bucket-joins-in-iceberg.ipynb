{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f676cad0-ac22-4bac-9122-38b1121b2f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://f9c8cdc0638d:4041\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1733499274162)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
       "matchesBucketed: org.apache.spark.sql.DataFrame = [match_id: string, mapid: string ... 8 more fields]\n",
       "matchDetailsBucketed: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 34 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// In python use: from pyspark.sql.functions import broadcast, split, lit\n",
    "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
    "\n",
    "\n",
    "val matchesBucketed = spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4152479-0d8f-42f4-a805-7614fe15f485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc012504-b1f3-41a4-944b-6bd0d2437b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucketedDDL: String =\n",
       "\"CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
       "                         match_id STRING,\n",
       "                         is_team_game BOOLEAN,\n",
       "                         playlist_id STRING,\n",
       "                         completion_date TIMESTAMP\n",
       "                     )\n",
       "                     USING iceberg;\n",
       "                     \"\n",
       "res1: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bucketedDDL = \"\"\"CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "                         match_id STRING,\n",
    "                         is_team_game BOOLEAN,\n",
    "                         playlist_id STRING,\n",
    "                         completion_date TIMESTAMP\n",
    "                     )\n",
    "                     USING iceberg;\n",
    "                     \"\"\"\n",
    "spark.sql(bucketedDDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a20945f-e820-4812-b1e8-e7e842970f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesBucketed.select($\"match_id\", $\"is_team_game\", $\"playlist_id\", $\"completion_date\")\n",
    "    .write.mode(\"append\")\n",
    "    .saveAsTable(\"bootcamp.matches_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc32cc76-1c6c-4c7d-bedb-67c2f9d7ca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+-------------------+\n",
      "|            match_id|is_team_game|         playlist_id|    completion_date|\n",
      "+--------------------+------------+--------------------+-------------------+\n",
      "|11de1a94-8d07-416...|        true|f72e0ef0-7c4a-430...|2016-02-22 00:00:00|\n",
      "|d3643e71-3e51-43e...|       false|d0766624-dbd7-453...|2016-02-14 00:00:00|\n",
      "|d78d2aae-36e4-48a...|        true|f72e0ef0-7c4a-430...|2016-03-24 00:00:00|\n",
      "|b440069e-ec5f-4f5...|        true|f72e0ef0-7c4a-430...|2015-12-23 00:00:00|\n",
      "|1dd475fc-ee6b-4e1...|        true|0e39ead4-383b-445...|2016-04-07 00:00:00|\n",
      "+--------------------+------------+--------------------+-------------------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   24025|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// After creating table\n",
    "spark.sql(\"SELECT * FROM bootcamp.matches_bucketed LIMIT 5\").show()\n",
    "\n",
    "// After writing data\n",
    "spark.sql(\"SELECT COUNT(*) FROM bootcamp.matches_bucketed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113533d-894b-4b9e-98fe-02f200ba5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "val bucketedDetailsDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    " spark.sql(bucketedDetailsDDL)\n",
    "\n",
    "matchDetailsBucketed.select(\n",
    "    $\"match_id\", $\"player_gamertag\", $\"player_total_kills\", $\"player_total_deaths\")\n",
    "    .write.mode(\"append\")\n",
    "  .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e247e50-92d4-4793-b42a-0aeb3d7f720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "matchesBucketed.createOrReplaceTempView(\"matches\")\n",
    "matchDetailsBucketed.createOrReplaceTempView(\"match_details\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM bootcamp.match_details_bucketed mdb JOIN bootcamp.matches_bucketed md \n",
    "    ON mdb.match_id = md.match_id\n",
    "    AND md.completion_date = DATE('2016-01-01')    \n",
    "\"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b48d10-7ddc-4d74-ad45-e1b033849cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM match_details mdb JOIN matches md ON mdb.match_id = md.match_id\n",
    "        \n",
    "\"\"\").explain()\n",
    "\n",
    " spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"1000000000000\")\n",
    "\n",
    " val broadcastFromThreshold = matches.as(\"m\").join(matchDetails.as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "   .select($\"m.completion_date\", $\"md.player_gamertag\",  $\"md.player_total_kills\")\n",
    "   .take(5)\n",
    "\n",
    " val explicitBroadcast = matches.as(\"m\").join(broadcast(matchDetails).as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "   .select($\"md.*\", split($\"completion_date\", \" \").getItem(0).as(\"ds\"))\n",
    "\n",
    " val bucketedValues = matchDetailsBucketed.as(\"mdb\").join(matchesBucketed.as(\"mb\"), $\"mb.match_id\" === $\"mdb.match_id\").explain()\n",
    " .take(5)\n",
    "\n",
    " val values = matchDetailsBucketed.as(\"m\").join(matchesBucketed.as(\"md\"), $\"m.match_id\" === $\"md.match_id\").explain()\n",
    "\n",
    " explicitBroadcast.write.mode(\"overwrite\").insertInto(\"match_details_bucketed\")\n",
    "\n",
    " matches.withColumn(\"ds\", split($\"completion_date\", \" \").getItem(0)).write.mode(\"overwrite\").insertInto(\"matches_bucketed\")\n",
    "\n",
    " spark.sql(bucketedSQL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8adb02-d5bd-4e84-a671-48991772d233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1eecb6-ca9a-4b5c-b046-b3a0dd1ff3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f879999-b51c-4f61-b2a1-35a6b0625aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
